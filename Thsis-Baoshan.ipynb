{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2eff434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 2024 Adyen Annual Report.pdf\n",
      "✅ ESRS pages: [112, 113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LLM error on page 112: Error code: 401 - {'error': {'message': 'Incorrect API key provided: input_yo***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "ERROR:root:LLM error on page 113: Error code: 401 - {'error': {'message': 'Incorrect API key provided: input_yo***********here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: annual-report-adidas-ar24.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    125\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Finished. Output saved to all_esrs_results.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Run the batch processor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mprocess_reports_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mprocess_reports_folder\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    109\u001b[39m     company = get_company_name(pdf_path)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     pages = \u001b[43mfind_esrs_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pages:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m❌ No ESRS pages found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mfind_esrs_pages\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     36\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [p + \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pages]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m qualifies = [code_cnt(\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) >= MIN_CODES \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m doc]\n\u001b[32m     40\u001b[39m blocks, i = [], \u001b[32m0\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i < \u001b[38;5;28mlen\u001b[39m(doc):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ESRS Extract Code/.venv/lib/python3.13/site-packages/pymupdf/utils.py:984\u001b[39m, in \u001b[36mget_text\u001b[39m\u001b[34m(page, option, clip, flags, textpage, sort, delimiters, tolerance)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;66;03m#pymupdf.exception_info()\u001b[39;00m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     tp = \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(tp, \u001b[33m\"\u001b[39m\u001b[33mparent\u001b[39m\u001b[33m\"\u001b[39m) != page:\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnot a textpage of this page\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ESRS Extract Code/.venv/lib/python3.13/site-packages/pymupdf/__init__.py:9353\u001b[39m, in \u001b[36mPage.get_textpage\u001b[39m\u001b[34m(self, clip, flags, matrix)\u001b[39m\n\u001b[32m   9351\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_rotation(\u001b[32m0\u001b[39m)\n\u001b[32m   9352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m9353\u001b[39m     textpage = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9354\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   9355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m old_rotation != \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ESRS Extract Code/.venv/lib/python3.13/site-packages/pymupdf/__init__.py:7908\u001b[39m, in \u001b[36mPage._get_textpage\u001b[39m\u001b[34m(self, clip, flags, matrix)\u001b[39m\n\u001b[32m   7906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_textpage\u001b[39m(\u001b[38;5;28mself\u001b[39m, clip=\u001b[38;5;28;01mNone\u001b[39;00m, flags=\u001b[32m0\u001b[39m, matrix=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   7907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m g_use_extra:\n\u001b[32m-> \u001b[39m\u001b[32m7908\u001b[39m         ll_tpage = \u001b[43mextra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7909\u001b[39m         tpage = mupdf.FzStextPage(ll_tpage)\n\u001b[32m   7910\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tpage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ESRS Extract Code/.venv/lib/python3.13/site-packages/pymupdf/extra.py:195\u001b[39m, in \u001b[36mpage_get_textpage\u001b[39m\u001b[34m(_self, clip, flags, matrix)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpage_get_textpage\u001b[39m(_self, clip, flags, matrix):\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extra\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_get_textpage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import openai\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json, logging\n",
    "\n",
    "load_dotenv()  # loads environment variables from .env file\n",
    "client = OpenAI(api_key=\"input_your_api_key_here\")  # replace with your OpenAI API key\n",
    "\n",
    "\n",
    "# --- Config ---\n",
    "CATEGORY = \"DR\"\n",
    "MAX_PAGE_COLS = 6\n",
    "REPORTS_DIR = \"Reports\"\n",
    "CODE_RE = re.compile(r'\\b(?:BP|GOV|SBM|IRO|E[1-5]|S[1-4]|G[1-3])[-\\u2013\\u2014\\u2010]?\\d{1,2}\\b', re.I)\n",
    "MIN_CODES = 5\n",
    "\n",
    "def code_cnt(txt: str) -> int:\n",
    "    return len(CODE_RE.findall(txt))\n",
    "\n",
    "def find_esrs_pages(pdf_path: str) -> List[int]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    toc_hits = [i for i, p in enumerate(doc)\n",
    "                if \"esrs table of contents\" in p.get_text().lower() and code_cnt(p.get_text()) >= MIN_CODES]\n",
    "    if toc_hits:\n",
    "        start = toc_hits[-1]\n",
    "        pages = [start]\n",
    "        for j in range(start + 1, len(doc)):\n",
    "            if code_cnt(doc[j].get_text()) >= MIN_CODES:\n",
    "                pages.append(j)\n",
    "            else:\n",
    "                break\n",
    "        return [p + 1 for p in pages]\n",
    "\n",
    "    qualifies = [code_cnt(p.get_text()) >= MIN_CODES for p in doc]\n",
    "    blocks, i = [], 0\n",
    "    while i < len(doc):\n",
    "        if not qualifies[i]: i += 1; continue\n",
    "        start = i\n",
    "        while i < len(doc) and qualifies[i]: i += 1\n",
    "        blocks.append(range(start, i))\n",
    "    if not blocks:\n",
    "        return []\n",
    "\n",
    "    best = max(blocks, key=lambda r: len(r) * sum(code_cnt(doc[p].get_text()) for p in r))\n",
    "    return [p + 1 for p in best]\n",
    "\n",
    "def clean_page_refs(ref_str: str, current_page: int) -> str:\n",
    "    toks = re.split(r\"[, \\s]+\", ref_str.strip())\n",
    "    refs = []\n",
    "    for t in toks:\n",
    "        if t.isdigit():\n",
    "            n = int(t)\n",
    "            if n == current_page or n < 10:\n",
    "                continue\n",
    "            refs.append(str(n))\n",
    "    return \", \".join(refs)\n",
    "\n",
    "def get_company_name(pdf_path: str) -> str:\n",
    "    filename = os.path.basename(pdf_path).lower()\n",
    "    clean_name = (filename.replace('-', ' ').replace('_', ' ').replace('.pdf', '')\n",
    "                  .replace('annual', '').replace('report', '').replace('group', '').replace('integrated', '').strip())\n",
    "    first_word = clean_name.split()[0].title()\n",
    "    return first_word if len(first_word) > 2 else os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "def extract_page_items(text: str, page_num: int, client: OpenAI, company: str) -> pd.DataFrame:\n",
    "    prompt = f\"\"\"You are an ESRS disclosure analyzer. Extract **all** ESRS disclosures from the text below (page {page_num}).\n",
    "    Return JSON exactly like: {{\\\"items\\\":[{{\\\"code\\\":\\\"\\\",\\\"title\\\":\\\"\\\",\\\"page_reference\\\":\\\"\\\"}}]}}\n",
    "\n",
    "Text:\\n{text}\"\"\"\n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        data = json.loads(resp.choices[0].message.content)\n",
    "        items: List[Dict] = data.get(\"items\", [])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM error on page {page_num}: {e}\")\n",
    "        items = []\n",
    "\n",
    "    if not items:\n",
    "        return pd.DataFrame(columns=[\"name\", \"category\", \"variable\", \"value\"] + [f\"Page_ref{i}\" for i in range(1, MAX_PAGE_COLS + 1)])\n",
    "\n",
    "    df = pd.DataFrame(items)\n",
    "    df[\"page_reference\"] = df[\"page_reference\"].apply(lambda x: \", \".join(map(str, x)) if isinstance(x, (list, tuple)) else str(x or \"\"))\n",
    "    df[\"page_reference\"] = df[\"page_reference\"].apply(lambda s: clean_page_refs(s, page_num))\n",
    "    df = df.groupby(\"code\", as_index=False, sort=False).agg({\"page_reference\": \", \".join})\n",
    "    df[\"value\"] = (df[\"page_reference\"].str.len() > 0).astype(int)\n",
    "    df = df.assign(name=company, category=CATEGORY, variable=df.get(\"code\")).drop(columns=[\"title\"], errors=\"ignore\")\n",
    "    pages = df[\"page_reference\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip().str.split(r\"[,\\s]+\", expand=True).rename(columns=lambda i: f\"Page_ref{i + 1}\")\n",
    "    for i in range(pages.shape[1] + 1, MAX_PAGE_COLS + 1):\n",
    "        pages[f\"Page_ref{i}\"] = \"\"\n",
    "    df = pd.concat([df.drop(columns=[\"page_reference\"]), pages], axis=1)\n",
    "    return df.fillna(\"\")\n",
    "\n",
    "def process_reports_folder():\n",
    "    summary = []\n",
    "    pdf_files = [f for f in os.listdir(REPORTS_DIR) if f.endswith(\".pdf\")]\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(REPORTS_DIR, pdf_file)\n",
    "        print(f\"\\nProcessing: {pdf_file}\")\n",
    "        try:\n",
    "            company = get_company_name(pdf_path)\n",
    "            pages = find_esrs_pages(pdf_path)\n",
    "            if not pages:\n",
    "                print(\"❌ No ESRS pages found\")\n",
    "                continue\n",
    "            print(f\"✅ ESRS pages: {pages}\")\n",
    "            doc = fitz.open(pdf_path)\n",
    "            dfs = [extract_page_items(doc[p - 1].get_text(), p, client, company) for p in pages]\n",
    "            full_table = pd.concat(dfs, ignore_index=True)\n",
    "            full_table[\"source\"] = pdf_file\n",
    "            summary.append(full_table)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {pdf_file}: {e}\")\n",
    "    if summary:\n",
    "        all_data = pd.concat(summary, ignore_index=True)\n",
    "        all_data.to_csv(\"all_esrs_results.csv\", index=False)\n",
    "        print(\"\\n✅ Finished. Output saved to all_esrs_results.csv\")\n",
    "\n",
    "# Run the batch processor\n",
    "process_reports_folder()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
